{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Sparse Representation Classificator (SRC)</h1>\n",
        "\n",
        " <h2> $\\min \\|s\\|_1 \\quad \\text{subject to} \\quad y = \\Theta s$ </h2>\n",
        "<h2> Where s is the sparse vector, y is the measument and  $\\Theta$ the measument matrix.\n",
        "\n",
        "<h3> To classify a test image, we aim to find the sparsest vector ùë†, where ùë¶ is a vectorized image and Œò is a collection of vectorized images of the 10 different handwritten digits, ordered sequentially.\n",
        "The positions in\n",
        "ùë†\n",
        "s with the highest values correspond to the columns in\n",
        "Œò\n",
        "that most closely represent the input image.\n",
        "We have\n",
        "ùëõ\n",
        "images for each digit. The classification is given by:</h3>\n",
        "\n",
        "<h3>\n",
        "$\\lfloor \\frac{i}{n} \\rfloor $ where $ s_i = \\max_{s_j \\in s} s_j$ </h3>.\n"
      ],
      "metadata": {
        "id": "1raMi-Xs-rpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Libraries</h1>"
      ],
      "metadata": {
        "id": "l9Xb5QHZ0pX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For vector and matrix manipulation\n",
        "import numpy as np\n",
        "\n",
        "# For import dataset\n",
        "import tensorflow as tf\n",
        "\n",
        "# For image manipulation\n",
        "from PIL import Image\n",
        "\n",
        "# For optimazation problem\n",
        "from sklearn.linear_model import Lasso"
      ],
      "metadata": {
        "id": "rHKYdj6XDHX5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from tensorflow\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdghMEROF_-G",
        "outputId": "76ebac19-9002-4e22-fe36-600e14dd3c3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All digit should have the same quantity of images, i choose 100 images\n",
        "\n",
        "def get_indexes(lst, element):\n",
        "    return [index for index, value in enumerate(lst) if value == element]\n",
        "\n",
        "def reduct_samples(lst, x_train, elements, n):\n",
        "  from random import randint\n",
        "\n",
        "  for element in elements:\n",
        "\n",
        "    indices = get_indexes(lst, element)\n",
        "    while len(indices) > n:\n",
        "\n",
        "      indices = get_indexes(lst, element)\n",
        "      random_index = randint(0, len(indices) - 1)\n",
        "\n",
        "      lst = np.delete(lst, indices[random_index])\n",
        "      x_train = np.delete(x_train, indices[random_index], axis = 0)\n",
        "      indices.pop(random_index)\n",
        "\n",
        "\n",
        "  return (lst, x_train)\n",
        "\n",
        "# 100 images\n",
        "(lst, x_train) = reduct_samples(y_train, x_train, range(10), 100)\n",
        "\n",
        "# new y_train with reducted samples\n",
        "y_train = lst\n",
        "\n",
        "\n",
        "# Vectorizing and concatenation in order ( 100 images for 0, 100 images for 1, 100 images for 2 ...)\n",
        "columns = []\n",
        "for i in range(10):\n",
        "\n",
        "  indices = get_indexes(y_train, i)\n",
        "\n",
        "  for index in indices:\n",
        "\n",
        "    image = x_train[index]\n",
        "    image_flatten = image.flatten().reshape(-1, 1)\n",
        "    columns.append(image_flatten)\n",
        "\n",
        "Theta = np.hstack(columns)"
      ],
      "metadata": {
        "id": "U7m0XtiBD8zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# I save the Theta matrix in a image so i dont need to run the reduction sample algorithm\n",
        "Theta = np.array(Image.open(\"Theta.png\"))"
      ],
      "metadata": {
        "id": "Ni4peDfXtoYu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoLars\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# less alpha = less sparse\n",
        "model = LassoLars(alpha=0.001, fit_intercept=False)\n"
      ],
      "metadata": {
        "id": "ipm4ID47ZTvh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = []\n",
        "\n",
        "# 100 tests\n",
        "for im, tr  in zip(x_test[:300], y_test[:300]):\n",
        "\n",
        "  model.fit(Theta, im.reshape(-1, 1))\n",
        "  s_sparse = model.coef_\n",
        "  pos = s_sparse.argmax() // 100\n",
        "\n",
        "  if(pos == tr):\n",
        "    test.append(1)\n",
        "\n",
        "  else:\n",
        "    test.append(0)\n",
        "\n",
        "\n",
        "# 77% of correct classifications alpha = 0.001\n",
        "\n",
        "sum(test)/len(test) * 100"
      ],
      "metadata": {
        "id": "neJXXli2axN_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}